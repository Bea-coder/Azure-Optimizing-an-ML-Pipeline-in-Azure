{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.core import Dataset, Datastore\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "data_path='https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv'\n",
        "ds =Dataset.Tabular.from_delimited_files(path=data_path)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1608667587120
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "def clean_data(data):\n",
        "    # Dict for cleaning data\n",
        "    months = {\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}\n",
        "    weekdays = {\"mon\":1, \"tue\":2, \"wed\":3, \"thu\":4, \"fri\":5, \"sat\":6, \"sun\":7}\n",
        "\n",
        "    # Clean and one hot encode data\n",
        "    print(\"data to pandas\")\n",
        "    x_df = data.to_pandas_dataframe().dropna()\n",
        "    print(\"one hot encode\")\n",
        "    jobs = pd.get_dummies(x_df.job, prefix=\"job\")\n",
        "    print(\"job dropped\")\n",
        "    x_df.drop(\"job\", inplace=True, axis=1)\n",
        "    print(\"adding jobs\")\n",
        "    x_df = x_df.join(jobs)\n",
        "    print(\"more cleaning\")\n",
        "    x_df[\"marital\"] = x_df.marital.apply(lambda s: 1 if s == \"married\" else 0)\n",
        "    x_df[\"default\"] = x_df.default.apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "    x_df[\"housing\"] = x_df.housing.apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "    x_df[\"loan\"] = x_df.loan.apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "    print(\"one hot contact\")\n",
        "    contact = pd.get_dummies(x_df.contact, prefix=\"contact\")\n",
        "    x_df.drop(\"contact\", inplace=True, axis=1)\n",
        "    x_df = x_df.join(contact)\n",
        "    print(\"one hot education\")\n",
        "    education = pd.get_dummies(x_df.education, prefix=\"education\")\n",
        "    x_df.drop(\"education\", inplace=True, axis=1)\n",
        "    x_df = x_df.join(education)\n",
        "    print(\"maping\")\n",
        "    x_df[\"month\"] = x_df.month.map(months)\n",
        "    x_df[\"day_of_week\"] = x_df.day_of_week.map(weekdays)\n",
        "    x_df[\"poutcome\"] = x_df.poutcome.apply(lambda s: 1 if s == \"success\" else 0)\n",
        "    print(\"end\")\n",
        "    y_df = x_df.pop(\"y\").apply(lambda s: 1 if s == \"yes\" else 0)\n",
        "    return x_df,y_df"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1608667604050
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=ds.to_pandas_dataframe()\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "   age          job  marital    education  default housing loan    contact  \\\n0   57   technician  married  high.school       no      no  yes   cellular   \n1   55      unknown  married      unknown  unknown     yes   no  telephone   \n2   33  blue-collar  married     basic.9y       no      no   no   cellular   \n3   36       admin.  married  high.school       no      no   no  telephone   \n4   27    housemaid  married  high.school       no     yes   no   cellular   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n0   may         mon  ...         1    999         1      failure         -1.8   \n1   may         thu  ...         2    999         0  nonexistent          1.1   \n2   may         fri  ...         1    999         1      failure         -1.8   \n3   jun         fri  ...         4    999         0  nonexistent          1.4   \n4   jul         fri  ...         2    999         0  nonexistent          1.4   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n0          92.893          -46.2      1.299       5099.1  no  \n1          93.994          -36.4      4.860       5191.0  no  \n2          92.893          -46.2      1.313       5099.1  no  \n3          94.465          -41.8      4.967       5228.1  no  \n4          93.918          -42.7      4.963       5228.1  no  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.299</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>unknown</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>thu</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.860</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>basic.9y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.313</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>4</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.967</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>93.918</td>\n      <td>-42.7</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608667591376
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the clean_data function to clean your data.\n",
        "### YOUR DATA OBJECT HERE ###)\n",
        "x, y = clean_data(ds)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data to pandas\n",
            "one hot encode\n",
            "job dropped\n",
            "adding jobs\n",
            "more cleaning\n",
            "one hot contact\n",
            "one hot education\n",
            "maping\n",
            "end\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1608667613872
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data=x.join(y)\n",
        "training_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "   age  marital  default  housing  loan  month  day_of_week  duration  \\\n0   57        1        0        0     1      5            1       371   \n1   55        1        0        1     0      5            4       285   \n2   33        1        0        0     0      5            5        52   \n3   36        1        0        0     0      6            5       355   \n4   27        1        0        1     0      7            5       189   \n\n   campaign  pdays  ...  contact_telephone  education_basic.4y  \\\n0         1    999  ...                  0                   0   \n1         2    999  ...                  1                   0   \n2         1    999  ...                  0                   0   \n3         4    999  ...                  1                   0   \n4         2    999  ...                  0                   0   \n\n   education_basic.6y  education_basic.9y  education_high.school  \\\n0                   0                   0                      1   \n1                   0                   0                      0   \n2                   0                   1                      0   \n3                   0                   0                      1   \n4                   0                   0                      1   \n\n   education_illiterate  education_professional.course  \\\n0                     0                              0   \n1                     0                              0   \n2                     0                              0   \n3                     0                              0   \n4                     0                              0   \n\n   education_university.degree  education_unknown  y  \n0                            0                  0  0  \n1                            0                  1  0  \n2                            0                  0  0  \n3                            0                  0  0  \n4                            0                  0  0  \n\n[5 rows x 40 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>marital</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>...</th>\n      <th>contact_telephone</th>\n      <th>education_basic.4y</th>\n      <th>education_basic.6y</th>\n      <th>education_basic.9y</th>\n      <th>education_high.school</th>\n      <th>education_illiterate</th>\n      <th>education_professional.course</th>\n      <th>education_university.degree</th>\n      <th>education_unknown</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>371</td>\n      <td>1</td>\n      <td>999</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>285</td>\n      <td>2</td>\n      <td>999</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>52</td>\n      <td>1</td>\n      <td>999</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>5</td>\n      <td>355</td>\n      <td>4</td>\n      <td>999</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>5</td>\n      <td>189</td>\n      <td>2</td>\n      <td>999</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608667617377
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=\"classification\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    training_data=training_data,\n",
        "    label_column_name=\"y\",\n",
        "    n_cross_validations=5)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1608667622495
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "#change myworspace name accordingly\n",
        "ws = Workspace.get(name=\"myworkspace\")\n",
        "# Submit your automl run\n",
        "experiment = Experiment(ws, \"automl_test_experiment\")\n",
        "run = experiment.submit(config=automl_config, show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on local machine\n",
            "Parent Run ID: AutoML_a1808ad5-6add-4e8e-b1c6-7c3b6aca8101\n",
            "\n",
            "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
            "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
            "Current status: DatasetBalancing. Performing class balancing sweeping\n",
            "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       ALERTED\n",
            "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
            "+=================================+=================================+======================================+\n",
            "|3692                             |1                                |32950                                 |\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  No feature missing values were detected in the training data.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:00:43       0.9151    0.9151\n",
            "         1   MaxAbsScaler XGBoostClassifier                 0:00:51       0.9149    0.9151\n",
            "         2   MaxAbsScaler RandomForest                      0:00:50       0.8935    0.9151\n",
            "         3   MaxAbsScaler RandomForest                      0:00:40       0.8880    0.9151\n",
            "         4   MaxAbsScaler RandomForest                      0:00:37       0.8098    0.9151\n",
            "         5   MaxAbsScaler RandomForest                      0:00:34       0.7412    0.9151\n",
            "         6   SparseNormalizer XGBoostClassifier             0:00:48       0.9110    0.9151\n",
            "         7   MaxAbsScaler GradientBoosting                  0:00:41       0.9029    0.9151\n",
            "         8   StandardScalerWrapper RandomForest             0:00:33       0.9012    0.9151\n",
            "         9   MaxAbsScaler LogisticRegression                0:00:38       0.9085    0.9151\n",
            "        10   MaxAbsScaler ExtremeRandomTrees                0:02:37       0.8880    0.9151\n",
            "        11   SparseNormalizer XGBoostClassifier             0:00:51       0.9111    0.9151\n",
            "        12   MaxAbsScaler LightGBM                          0:00:32       0.8910    0.9151\n",
            "        13   MaxAbsScaler LightGBM                          0:00:40       0.9050    0.9151\n",
            "        14   SparseNormalizer XGBoostClassifier             0:01:50       0.9139    0.9151\n",
            "        15   StandardScalerWrapper LightGBM                 0:00:34       0.8950    0.9151\n",
            "        16   StandardScalerWrapper RandomForest             0:00:54       0.8880    0.9151\n",
            "        17   StandardScalerWrapper LightGBM                 0:00:31       0.8880    0.9151\n",
            "        18   StandardScalerWrapper ExtremeRandomTrees       0:00:54       0.8880    0.9151\n",
            "        19   StandardScalerWrapper LightGBM                 0:00:31       0.9042    0.9151\n",
            "        20   SparseNormalizer XGBoostClassifier             0:00:34       0.9124    0.9151\n",
            "        21   MaxAbsScaler LightGBM                          0:00:26       0.8881    0.9151\n",
            "        22   SparseNormalizer LightGBM                      0:00:42       0.9049    0.9151\n",
            "        23   SparseNormalizer LightGBM                      0:00:39       0.9117    0.9151\n",
            "        24   StandardScalerWrapper LightGBM                 0:00:41       0.9081    0.9151\n",
            "        25   SparseNormalizer LightGBM                      0:00:28       0.8880    0.9151\n",
            "        26   SparseNormalizer LightGBM                      0:00:35       0.9121    0.9151\n",
            "        27   SparseNormalizer XGBoostClassifier             0:00:46       0.9150    0.9151\n",
            "        28   StandardScalerWrapper LightGBM                 0:00:28       0.8921    0.9151\n",
            "        29   SparseNormalizer XGBoostClassifier             0:00:44       0.9153    0.9153\n",
            "        30   SparseNormalizer XGBoostClassifier             0:00:35       0.8880    0.9153\n",
            "        31   SparseNormalizer XGBoostClassifier             0:01:01       0.9141    0.9153\n",
            "        32   StandardScalerWrapper XGBoostClassifier        0:00:46       0.9084    0.9153\n",
            "        33   MaxAbsScaler GradientBoosting                  0:00:59       0.9027    0.9153\n",
            "        34   StandardScalerWrapper XGBoostClassifier        0:00:48       0.9164    0.9164\n",
            "        35   SparseNormalizer XGBoostClassifier             0:00:37       0.8880    0.9164\n",
            "        36   SparseNormalizer XGBoostClassifier             0:01:48       0.9121    0.9164\n",
            "        37   VotingEnsemble                                 0:01:30       0.9168    0.9168\n",
            "        38   StackEnsemble                                  0:02:07       0.9146    0.9168\n",
            "Stopping criteria reached at iteration 39. Ending experiment.\n",
            "****************************************************************************************************\n",
            "Current status: BestRunExplainModel. Best run model explanations started\n",
            "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
            "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
            "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
            "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
            "Current status: RawFeaturesExplanations. Computation of raw features started\n",
            "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
            "Current status: BestRunExplainModel. Best run model explanations completed\n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608669886160
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "best_run, model = run.get_output()\n",
        "estimator = model.steps[-1]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608669886980
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.steps)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
            "                feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
            "                featurization_config=None, force_text_dnn=None,\n",
            "                is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
            "                observer=None, task=None, working_dir=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
            "                              estimators=[('34',\n",
            "                                           Pipeline(memory=None,\n",
            "                                                    steps=[('standardscalerwrapper',\n",
            "                                                            <azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7f86388b02b0>),\n",
            "                                                           ('xgboostclassifier',\n",
            "                                                            XGBoostClassifier(base_score=0.5,\n",
            "                                                                              booster='gbtree',\n",
            "                                                                              colsample_bylevel=1,\n",
            "                                                                              colsample_bynode=1,\n",
            "                                                                              colsample_bytree=0.7...\n",
            "                                                                               reg_lambda=0.42105263157894735,\n",
            "                                                                               silent=True,\n",
            "                                                                               subsample=0.05,\n",
            "                                                                               subsample_for_bin=200000,\n",
            "                                                                               subsample_freq=0,\n",
            "                                                                               verbose=-10))],\n",
            "                                                    verbose=False))],\n",
            "                              flatten_transform=None,\n",
            "                              weights=[0.14285714285714285, 0.21428571428571427,\n",
            "                                       0.07142857142857142, 0.14285714285714285,\n",
            "                                       0.07142857142857142, 0.07142857142857142,\n",
            "                                       0.07142857142857142, 0.07142857142857142,\n",
            "                                       0.07142857142857142,\n",
            "                                       0.07142857142857142]))]\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608669892553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def print_model(model, prefix=\"\"):\n",
        "    for step in model.steps:\n",
        "        print(prefix + step[0])\n",
        "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
        "            pprint({'estimators': list(\n",
        "                e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
        "            print()\n",
        "            for estimator in step[1].estimators:\n",
        "                print_model(estimator[1], estimator[0] + ' - ')\n",
        "        else:\n",
        "            pprint(step[1].get_params())\n",
        "            print()\n",
        "\n",
        "print_model(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datatransformer\n",
            "{'enable_dnn': None,\n",
            " 'enable_feature_sweeping': None,\n",
            " 'feature_sweeping_config': None,\n",
            " 'feature_sweeping_timeout': None,\n",
            " 'featurization_config': None,\n",
            " 'force_text_dnn': None,\n",
            " 'is_cross_validation': None,\n",
            " 'is_onnx_compatible': None,\n",
            " 'logger': None,\n",
            " 'observer': None,\n",
            " 'task': None,\n",
            " 'working_dir': None}\n",
            "\n",
            "prefittedsoftvotingclassifier\n",
            "{'estimators': ['34', '29', '0', '27', '1', '31', '4', '20', '26', '24'],\n",
            " 'weights': [0.14285714285714285,\n",
            "             0.21428571428571427,\n",
            "             0.07142857142857142,\n",
            "             0.14285714285714285,\n",
            "             0.07142857142857142,\n",
            "             0.07142857142857142,\n",
            "             0.07142857142857142,\n",
            "             0.07142857142857142,\n",
            "             0.07142857142857142,\n",
            "             0.07142857142857142]}\n",
            "\n",
            "34 - standardscalerwrapper\n",
            "{'class_name': 'StandardScaler',\n",
            " 'copy': True,\n",
            " 'module_name': 'sklearn.preprocessing._data',\n",
            " 'with_mean': False,\n",
            " 'with_std': False}\n",
            "\n",
            "34 - xgboostclassifier\n",
            "{'base_score': 0.5,\n",
            " 'booster': 'gbtree',\n",
            " 'colsample_bylevel': 1,\n",
            " 'colsample_bynode': 1,\n",
            " 'colsample_bytree': 0.7,\n",
            " 'eta': 0.1,\n",
            " 'gamma': 0,\n",
            " 'learning_rate': 0.1,\n",
            " 'max_delta_step': 0,\n",
            " 'max_depth': 5,\n",
            " 'max_leaves': 0,\n",
            " 'min_child_weight': 1,\n",
            " 'missing': nan,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': 1,\n",
            " 'nthread': None,\n",
            " 'objective': 'reg:logistic',\n",
            " 'random_state': 0,\n",
            " 'reg_alpha': 1.0416666666666667,\n",
            " 'reg_lambda': 1.9791666666666667,\n",
            " 'scale_pos_weight': 1,\n",
            " 'seed': None,\n",
            " 'silent': None,\n",
            " 'subsample': 1,\n",
            " 'tree_method': 'auto',\n",
            " 'verbose': -10,\n",
            " 'verbosity': 0}\n",
            "\n",
            "29 - sparsenormalizer\n",
            "{'copy': True, 'norm': 'max'}\n",
            "\n",
            "29 - xgboostclassifier\n",
            "{'base_score': 0.5,\n",
            " 'booster': 'gbtree',\n",
            " 'colsample_bylevel': 1,\n",
            " 'colsample_bynode': 1,\n",
            " 'colsample_bytree': 0.9,\n",
            " 'eta': 0.01,\n",
            " 'gamma': 0,\n",
            " 'learning_rate': 0.1,\n",
            " 'max_delta_step': 0,\n",
            " 'max_depth': 4,\n",
            " 'max_leaves': 0,\n",
            " 'min_child_weight': 1,\n",
            " 'missing': nan,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': 1,\n",
            " 'nthread': None,\n",
            " 'objective': 'reg:logistic',\n",
            " 'random_state': 0,\n",
            " 'reg_alpha': 1.0416666666666667,\n",
            " 'reg_lambda': 0.7291666666666667,\n",
            " 'scale_pos_weight': 1,\n",
            " 'seed': None,\n",
            " 'silent': None,\n",
            " 'subsample': 1,\n",
            " 'tree_method': 'auto',\n",
            " 'verbose': -10,\n",
            " 'verbosity': 0}\n",
            "\n",
            "0 - maxabsscaler\n",
            "{'copy': True}\n",
            "\n",
            "0 - lightgbmclassifier\n",
            "{'boosting_type': 'gbdt',\n",
            " 'class_weight': None,\n",
            " 'colsample_bytree': 1.0,\n",
            " 'importance_type': 'split',\n",
            " 'learning_rate': 0.1,\n",
            " 'max_depth': -1,\n",
            " 'min_child_samples': 20,\n",
            " 'min_child_weight': 0.001,\n",
            " 'min_split_gain': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': 1,\n",
            " 'num_leaves': 31,\n",
            " 'objective': None,\n",
            " 'random_state': None,\n",
            " 'reg_alpha': 0.0,\n",
            " 'reg_lambda': 0.0,\n",
            " 'silent': True,\n",
            " 'subsample': 1.0,\n",
            " 'subsample_for_bin': 200000,\n",
            " 'subsample_freq': 0,\n",
            " 'verbose': -10}\n",
            "\n",
            "27 - sparsenormalizer\n",
            "{'copy': True, 'norm': 'l2'}\n",
            "\n",
            "27 - xgboostclassifier\n",
            "{'base_score': 0.5,\n",
            " 'booster': 'gbtree',\n",
            " 'colsample_bylevel': 1,\n",
            " 'colsample_bynode': 1,\n",
            " 'colsample_bytree': 0.5,\n",
            " 'eta': 0.001,\n",
            " 'gamma': 0.01,\n",
            " 'learning_rate': 0.1,\n",
            " 'max_delta_step': 0,\n",
            " 'max_depth': 5,\n",
            " 'max_leaves': 3,\n",
            " 'min_child_weight': 1,\n",
            " 'missing': nan,\n",
            " 'n_estimators': 50,\n",
            " 'n_jobs': 1,\n",
            " 'nthread': None,\n",
            " 'objective': 'reg:logistic',\n",
            " 'random_state': 0,\n",
            " 'reg_alpha': 1.3541666666666667,\n",
            " 'reg_lambda': 1.3541666666666667,\n",
            " 'scale_pos_weight': 1,\n",
            " 'seed': None,\n",
            " 'silent': None,\n",
            " 'subsample': 0.7,\n",
            " 'tree_method': 'auto',\n",
            " 'verbose': -10,\n",
            " 'verbosity': 0}\n",
            "\n",
            "1 - maxabsscaler\n",
            "{'copy': True}\n",
            "\n",
            "1 - xgboostclassifier\n",
            "{'base_score': 0.5,\n",
            " 'booster': 'gbtree',\n",
            " 'colsample_bylevel': 1,\n",
            " 'colsample_bynode': 1,\n",
            " 'colsample_bytree': 1,\n",
            " 'gamma': 0,\n",
            " 'learning_rate': 0.1,\n",
            " 'max_delta_step': 0,\n",
            " 'max_depth': 3,\n",
            " 'min_child_weight': 1,\n",
            " 'missing': nan,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': 1,\n",
            " 'nthread': None,\n",
            " 'objective': 'binary:logistic',\n",
            " 'random_state': 0,\n",
            " 'reg_alpha': 0,\n",
            " 'reg_lambda': 1,\n",
            " 'scale_pos_weight': 1,\n",
            " 'seed': None,\n",
            " 'silent': None,\n",
            " 'subsample': 1,\n",
            " 'tree_method': 'auto',\n",
            " 'verbose': -10,\n",
            " 'verbosity': 0}\n",
            "\n",
            "31 - sparsenormalizer\n",
            "{'copy': True, 'norm': 'l1'}\n",
            "\n",
            "31 - xgboostclassifier\n",
            "{'base_score': 0.5,\n",
            " 'booster': 'gbtree',\n",
            " 'colsample_bylevel': 1,\n",
            " 'colsample_bynode': 1,\n",
            " 'colsample_bytree': 0.5,\n",
            " 'eta': 0.3,\n",
            " 'gamma': 0,\n",
            " 'learning_rate': 0.1,\n",
            " 'max_delta_step': 0,\n",
            " 'max_depth': 6,\n",
            " 'max_leaves': 0,\n",
            " 'min_child_weight': 1,\n",
            " 'missing': nan,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': 1,\n",
            " 'nthread': None,\n",
            " 'objective': 'reg:logistic',\n",
            " 'random_state': 0,\n",
            " 'reg_alpha': 1.7708333333333335,\n",
            " 'reg_lambda': 2.5,\n",
            " 'scale_pos_weight': 1,\n",
            " 'seed': None,\n",
            " 'silent': None,\n",
            " 'subsample': 0.7,\n",
            " 'tree_method': 'auto',\n",
            " 'verbose': -10,\n",
            " 'verbosity': 0}\n",
            "\n",
            "4 - maxabsscaler\n",
            "{'copy': True}\n",
            "\n",
            "4 - randomforestclassifier\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': 'balanced',\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'log2',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 0.01,\n",
            " 'min_samples_split': 0.01,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 25,\n",
            " 'n_jobs': 1,\n",
            " 'oob_score': True,\n",
            " 'random_state': None,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "\n",
            "20 - sparsenormalizer\n",
            "{'copy': True, 'norm': 'l2'}\n",
            "\n",
            "20 - xgboostclassifier\n",
            "{'base_score': 0.5,\n",
            " 'booster': 'gbtree',\n",
            " 'colsample_bylevel': 1,\n",
            " 'colsample_bynode': 1,\n",
            " 'colsample_bytree': 0.7,\n",
            " 'eta': 0.3,\n",
            " 'gamma': 0,\n",
            " 'grow_policy': 'lossguide',\n",
            " 'learning_rate': 0.1,\n",
            " 'max_bin': 63,\n",
            " 'max_delta_step': 0,\n",
            " 'max_depth': 6,\n",
            " 'max_leaves': 3,\n",
            " 'min_child_weight': 1,\n",
            " 'missing': nan,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': 1,\n",
            " 'nthread': None,\n",
            " 'objective': 'reg:logistic',\n",
            " 'random_state': 0,\n",
            " 'reg_alpha': 1.0416666666666667,\n",
            " 'reg_lambda': 1.5625,\n",
            " 'scale_pos_weight': 1,\n",
            " 'seed': None,\n",
            " 'silent': None,\n",
            " 'subsample': 0.8,\n",
            " 'tree_method': 'hist',\n",
            " 'verbose': -10,\n",
            " 'verbosity': 0}\n",
            "\n",
            "26 - sparsenormalizer\n",
            "{'copy': True, 'norm': 'l1'}\n",
            "\n",
            "26 - lightgbmclassifier\n",
            "{'boosting_type': 'gbdt',\n",
            " 'class_weight': None,\n",
            " 'colsample_bytree': 0.1,\n",
            " 'importance_type': 'split',\n",
            " 'learning_rate': 0.08947473684210526,\n",
            " 'max_bin': 240,\n",
            " 'max_depth': 9,\n",
            " 'min_child_samples': 3068,\n",
            " 'min_child_weight': 0,\n",
            " 'min_split_gain': 0.9473684210526315,\n",
            " 'n_estimators': 400,\n",
            " 'n_jobs': 1,\n",
            " 'num_leaves': 194,\n",
            " 'objective': None,\n",
            " 'random_state': None,\n",
            " 'reg_alpha': 0.5789473684210527,\n",
            " 'reg_lambda': 0.631578947368421,\n",
            " 'silent': True,\n",
            " 'subsample': 0.6436842105263159,\n",
            " 'subsample_for_bin': 200000,\n",
            " 'subsample_freq': 0,\n",
            " 'verbose': -10}\n",
            "\n",
            "24 - standardscalerwrapper\n",
            "{'class_name': 'StandardScaler',\n",
            " 'copy': True,\n",
            " 'module_name': 'sklearn.preprocessing._data',\n",
            " 'with_mean': False,\n",
            " 'with_std': True}\n",
            "\n",
            "24 - lightgbmclassifier\n",
            "{'boosting_type': 'gbdt',\n",
            " 'class_weight': None,\n",
            " 'colsample_bytree': 0.4955555555555555,\n",
            " 'importance_type': 'split',\n",
            " 'learning_rate': 0.05789894736842106,\n",
            " 'max_bin': 210,\n",
            " 'max_depth': 5,\n",
            " 'min_child_samples': 2614,\n",
            " 'min_child_weight': 0,\n",
            " 'min_split_gain': 0.3684210526315789,\n",
            " 'n_estimators': 600,\n",
            " 'n_jobs': 1,\n",
            " 'num_leaves': 137,\n",
            " 'objective': None,\n",
            " 'random_state': None,\n",
            " 'reg_alpha': 0.5789473684210527,\n",
            " 'reg_lambda': 0.42105263157894735,\n",
            " 'silent': True,\n",
            " 'subsample': 0.05,\n",
            " 'subsample_for_bin': 200000,\n",
            " 'subsample_freq': 0,\n",
            " 'verbose': -10}\n",
            "\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608669899659
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run_metrics = best_run.get_metrics()\n",
        "print(best_run_metrics['accuracy'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9167830045523522\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608669952985
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.steps"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "[('datatransformer',\n  DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n                  feature_sweeping_config=None, feature_sweeping_timeout=None,\n                  featurization_config=None, force_text_dnn=None,\n                  is_cross_validation=None, is_onnx_compatible=None, logger=None,\n                  observer=None, task=None, working_dir=None)),\n ('prefittedsoftvotingclassifier',\n  PreFittedSoftVotingClassifier(classification_labels=None,\n                                estimators=[('34',\n                                             Pipeline(memory=None,\n                                                      steps=[('standardscalerwrapper',\n                                                              <azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7f86388b02b0>),\n                                                             ('xgboostclassifier',\n                                                              XGBoostClassifier(base_score=0.5,\n                                                                                booster='gbtree',\n                                                                                colsample_bylevel=1,\n                                                                                colsample_bynode=1,\n                                                                                colsample_bytree=0.7...\n                                                                                 reg_lambda=0.42105263157894735,\n                                                                                 silent=True,\n                                                                                 subsample=0.05,\n                                                                                 subsample_for_bin=200000,\n                                                                                 subsample_freq=0,\n                                                                                 verbose=-10))],\n                                                      verbose=False))],\n                                flatten_transform=None,\n                                weights=[0.14285714285714285, 0.21428571428571427,\n                                         0.07142857142857142, 0.14285714285714285,\n                                         0.07142857142857142, 0.07142857142857142,\n                                         0.07142857142857142, 0.07142857142857142,\n                                         0.07142857142857142,\n                                         0.07142857142857142]))]",
            "text/html": "[('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n                feature_sweeping_config=None, feature_sweeping_timeout=None,\n                featurization_config=None, force_text_dnn=None,\n                is_cross_validation=None, is_onnx_compatible=None, logger=None,\n                observer=None, task=None, working_dir=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n                              estimators=[('34',\n                                           Pipeline(memory=None,\n                                                    steps=[('standardscalerwrapper',\n                                                            <azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7f86388b02b0>),\n                                                           ('xgboostclassifier',\n                                                            XGBoostClassifier(base_score=0.5,\n                                                                              booster='gbtree',\n                                                                              colsample_bylevel=1,\n                                                                              colsample_bynode=1,\n                                                                              colsample_bytree=0.7...\n                                                                               reg_lambda=0.42105263157894735,\n                                                                               silent=True,\n                                                                               subsample=0.05,\n                                                                               subsample_for_bin=200000,\n                                                                               subsample_freq=0,\n                                                                               verbose=-10))],\n                                                    verbose=False))],\n                              flatten_transform=None,\n                              weights=[0.14285714285714285, 0.21428571428571427,\n                                       0.07142857142857142, 0.14285714285714285,\n                                       0.07142857142857142, 0.07142857142857142,\n                                       0.07142857142857142, 0.07142857142857142,\n                                       0.07142857142857142,\n                                       0.07142857142857142]))]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1608670070667
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}